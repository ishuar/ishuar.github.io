{"status":"ok","feed":{"url":"https://medium.com/feed/@ishuar","title":"Stories by Ishan Sharma on Medium","link":"https://medium.com/@ishuar?source=rss-6962bfed9f3------2","author":"","description":"Stories by Ishan Sharma on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/1*Dq1AEmqY4TU2hRidJesIQA.jpeg"},"items":[{"title":"\u201cMust-Have Tech Essentials for DevOps Success\u201d Part-01","pubDate":"2024-04-04 13:31:55","link":"https://ishuar.medium.com/must-have-tech-essentials-for-devops-success-part-01-ab1398987a21?source=rss-6962bfed9f3------2","guid":"https://medium.com/p/ab1398987a21","author":"Ishan Sharma","thumbnail":"","description":"\n<h4>TL;DR:</h4>\n<p>DevOps streamlines software development with collaboration, automation, and continuous enhancement. This blog talks about <strong>why</strong> DevOps is the talk of the tech town and introduces <strong>three</strong> key technical pillars: Linux, networking basics, and the public cloud. Stay tuned for <strong>part two</strong> to uncover the rest of the\u00a0puzzle.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2ZjWxHc-QPJsclGaQHm-Kw.png\"><figcaption>follow on Instagram @<a href=\"https://www.instagram.com/devopswithishan/\">devopswithishan</a></figcaption></figure><blockquote>Before going into technical details for DevOps essentials, let's try to understand DevOps and Why its so\u00a0popular?</blockquote>\n<h4>What is\u00a0DevOps?</h4>\n<p>DevOps is not just a set of tools, but a culture and a set of practices that bring together development (Dev) and operations (Ops) teams to collaborate more efficiently throughout the software development lifecycle. It\u2019s about breaking down silos, fostering communication, and automating processes to deliver high-quality software faster and more reliably.</p>\n<p><em>\u201cDevOps represents a transformative mindset and cultural evolution, guiding teams to embrace new working methods, foster collaboration, automate processes, and pursue continuous improvement.\u201d</em></p>\n<h4>What Makes DevOps Different?</h4>\n<p><strong><em>Breaking Silos:</em></strong> Traditional development and operations teams often work in isolation, leading to communication gaps. DevOps breaks down these silos, promoting collaboration and shared\u00a0goals.</p>\n<p><strong><em>Automation:</em></strong> DevOps heavily relies on automation to streamline processes, from code integration and testing to deployment and monitoring.</p>\n<p><strong><em>Continuous Integration/Continuous Deployment (CI/CD):</em></strong> DevOps emphasizes CI/CD pipelines, enabling frequent and reliable software releases.</p>\n<p><strong><em>Feedback Loops:</em></strong> Regular feedback loops, including monitoring and user feedback, allow for continuous improvement and faster issue resolution.</p>\n<h4>Technical Essentials For\u00a0DevOps</h4>\n<p>In the fast-paced world of DevOps, mastering key essentials lays the foundation for success. Let\u2019s explore some fundamental components and why they\u2019re crucial for DevOps aspirants, along with popular tools and technologies within each\u00a0domain.</p>\n<p>In total, I will outline <strong>seven</strong> <strong>key components</strong>. While three are covered in this section, the remaining four will be unveiled in the forthcoming second\u00a0part.</p>\n<p><strong>1. Linux Operating System</strong></p>\n<p>Linux is the backbone of many DevOps environments due to its flexibility, scalability, and robustness. It provides a reliable platform for hosting applications and services. Popular distributions include Ubuntu, CentOS, and Red Hat Enterprise Linux\u00a0(RHEL).</p>\n<p><strong>2. Fundamentals of Networking</strong></p>\n<p>Networking knowledge is essential for DevOps engineers to understand how systems communicate and interact. It enables efficient troubleshooting, optimization, and security management of network infrastructure.</p>\n<p><strong>3. At least One Public\u00a0Cloud</strong></p>\n<p>Public clouds offer scalability, flexibility, and cost-effectiveness for hosting applications and services. They provide access to a wide range of infrastructure and services on\u00a0demand.</p>\n<p>When it comes to cloud computing, there\u2019s no one-size-fits-all solution. <strong>Amazon Web Services</strong> (AWS), <strong>Microsoft Azure</strong>, and <strong>Google Cloud Platform</strong> (GCP) each offer unique features and services tailored to different business needs. Whether you opt for AWS, Azure, or GCP, you\u2019ll find a wealth of resources and support to help you navigate the complexities of cloud computing and achieve your desired outcomes.</p>\n<blockquote>\u201dDevOps Engineering is not at all limited to these concepts, but they are considered to be the most fundamental from the technical standpoint.</blockquote>\n<h4>Wrapping Up and Looking\u00a0Ahead</h4>\n<p>From a technical standpoint, these three essentials lay the foundation for successful DevOps implementation. These components provide the infrastructure and tools necessary for deploying, managing, and scaling modern applications in a dynamic environment.</p>\n<p>While this blog may have only scratched the surface of DevOps essentials, stay tuned for the second part where I\u2019ll delve deeper into additional essentials.</p>\n<p>Follow <a href=\"https://medium.com/u/6962bfed9f3\">Ishan Sharma</a> for updates, and for detailed versions of each point, visit my <a href=\"https://github.com/ishuar/zero-to-hero-devops-roadmap\">GitHub repository</a> where I am compiling (work in progress) comprehensive resources including text and video-based articles for seasoned and DevOps aspirants.</p>\n<p><a href=\"https://github.com/ishuar/zero-to-hero-devops-roadmap\">GitHub - ishuar/zero-to-hero-devops-roadmap</a></p>\n<p>Let\u2019s continue the journey towards mastering DevOps together!</p>\n<h4>Acknowledgment</h4>\n<p>Thank you for dedicating your time to exploring the essential components of DevOps with <a href=\"https://medium.com/u/6962bfed9f3\">Ishan Sharma</a>. Also, anticipate the forthcoming second part of the blog, where we\u2019ll unveil the final pieces of the\u00a0puzzle.</p>\n<p>Your continued engagement is invaluable.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ab1398987a21\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<h4>TL;DR:</h4>\n<p>DevOps streamlines software development with collaboration, automation, and continuous enhancement. This blog talks about <strong>why</strong> DevOps is the talk of the tech town and introduces <strong>three</strong> key technical pillars: Linux, networking basics, and the public cloud. Stay tuned for <strong>part two</strong> to uncover the rest of the\u00a0puzzle.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*2ZjWxHc-QPJsclGaQHm-Kw.png\"><figcaption>follow on Instagram @<a href=\"https://www.instagram.com/devopswithishan/\">devopswithishan</a></figcaption></figure><blockquote>Before going into technical details for DevOps essentials, let's try to understand DevOps and Why its so\u00a0popular?</blockquote>\n<h4>What is\u00a0DevOps?</h4>\n<p>DevOps is not just a set of tools, but a culture and a set of practices that bring together development (Dev) and operations (Ops) teams to collaborate more efficiently throughout the software development lifecycle. It\u2019s about breaking down silos, fostering communication, and automating processes to deliver high-quality software faster and more reliably.</p>\n<p><em>\u201cDevOps represents a transformative mindset and cultural evolution, guiding teams to embrace new working methods, foster collaboration, automate processes, and pursue continuous improvement.\u201d</em></p>\n<h4>What Makes DevOps Different?</h4>\n<p><strong><em>Breaking Silos:</em></strong> Traditional development and operations teams often work in isolation, leading to communication gaps. DevOps breaks down these silos, promoting collaboration and shared\u00a0goals.</p>\n<p><strong><em>Automation:</em></strong> DevOps heavily relies on automation to streamline processes, from code integration and testing to deployment and monitoring.</p>\n<p><strong><em>Continuous Integration/Continuous Deployment (CI/CD):</em></strong> DevOps emphasizes CI/CD pipelines, enabling frequent and reliable software releases.</p>\n<p><strong><em>Feedback Loops:</em></strong> Regular feedback loops, including monitoring and user feedback, allow for continuous improvement and faster issue resolution.</p>\n<h4>Technical Essentials For\u00a0DevOps</h4>\n<p>In the fast-paced world of DevOps, mastering key essentials lays the foundation for success. Let\u2019s explore some fundamental components and why they\u2019re crucial for DevOps aspirants, along with popular tools and technologies within each\u00a0domain.</p>\n<p>In total, I will outline <strong>seven</strong> <strong>key components</strong>. While three are covered in this section, the remaining four will be unveiled in the forthcoming second\u00a0part.</p>\n<p><strong>1. Linux Operating System</strong></p>\n<p>Linux is the backbone of many DevOps environments due to its flexibility, scalability, and robustness. It provides a reliable platform for hosting applications and services. Popular distributions include Ubuntu, CentOS, and Red Hat Enterprise Linux\u00a0(RHEL).</p>\n<p><strong>2. Fundamentals of Networking</strong></p>\n<p>Networking knowledge is essential for DevOps engineers to understand how systems communicate and interact. It enables efficient troubleshooting, optimization, and security management of network infrastructure.</p>\n<p><strong>3. At least One Public\u00a0Cloud</strong></p>\n<p>Public clouds offer scalability, flexibility, and cost-effectiveness for hosting applications and services. They provide access to a wide range of infrastructure and services on\u00a0demand.</p>\n<p>When it comes to cloud computing, there\u2019s no one-size-fits-all solution. <strong>Amazon Web Services</strong> (AWS), <strong>Microsoft Azure</strong>, and <strong>Google Cloud Platform</strong> (GCP) each offer unique features and services tailored to different business needs. Whether you opt for AWS, Azure, or GCP, you\u2019ll find a wealth of resources and support to help you navigate the complexities of cloud computing and achieve your desired outcomes.</p>\n<blockquote>\u201dDevOps Engineering is not at all limited to these concepts, but they are considered to be the most fundamental from the technical standpoint.</blockquote>\n<h4>Wrapping Up and Looking\u00a0Ahead</h4>\n<p>From a technical standpoint, these three essentials lay the foundation for successful DevOps implementation. These components provide the infrastructure and tools necessary for deploying, managing, and scaling modern applications in a dynamic environment.</p>\n<p>While this blog may have only scratched the surface of DevOps essentials, stay tuned for the second part where I\u2019ll delve deeper into additional essentials.</p>\n<p>Follow <a href=\"https://medium.com/u/6962bfed9f3\">Ishan Sharma</a> for updates, and for detailed versions of each point, visit my <a href=\"https://github.com/ishuar/zero-to-hero-devops-roadmap\">GitHub repository</a> where I am compiling (work in progress) comprehensive resources including text and video-based articles for seasoned and DevOps aspirants.</p>\n<p><a href=\"https://github.com/ishuar/zero-to-hero-devops-roadmap\">GitHub - ishuar/zero-to-hero-devops-roadmap</a></p>\n<p>Let\u2019s continue the journey towards mastering DevOps together!</p>\n<h4>Acknowledgment</h4>\n<p>Thank you for dedicating your time to exploring the essential components of DevOps with <a href=\"https://medium.com/u/6962bfed9f3\">Ishan Sharma</a>. Also, anticipate the forthcoming second part of the blog, where we\u2019ll unveil the final pieces of the\u00a0puzzle.</p>\n<p>Your continued engagement is invaluable.</p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ab1398987a21\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["agile","devops-engineer","software-development","development","devops"]},{"title":"Terraform and Ansible: Teaming Up for Automated Cloud Magic","pubDate":"2023-11-24 14:03:50","link":"https://ishuar.medium.com/terraform-and-ansible-teaming-up-for-automated-cloud-magic-70c6285a3dc1?source=rss-6962bfed9f3------2","guid":"https://medium.com/p/70c6285a3dc1","author":"Ishan Sharma","thumbnail":"","description":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SZqQC04atRiwZiUIC8YYOw.gif\"></figure><h3>TL;DR</h3>\n<p>In the world of cloud automation, Terraform and Ansible form a seamless partnership. Terraform constructs infrastructure, while Ansible configures it. Leveraging dynamic inventories and GitHub Actions, the process gains efficiency.</p>\n<p>Explore my <a href=\"https://github.com/ishuar/terraform-ansible-azure\">GitHub repository</a> for hands-on experience. Delve into Terraform\u2019s provisioning, Ansible\u2019s management, and GitHub\u2019s orchestration.</p>\n<p><em>Unlock cloud automation with Terraform, Ansible, and GitHub\u2019s\u00a0synergy.</em></p>\n<h3>Introduction</h3>\n<p>In the dynamic world of cloud computing, provisioning infrastructure, and managing configurations are essential tasks. This is where Terraform and Ansible come into play, acting as a dynamic duo that enables you to orchestrate automated cloud\u00a0magic.</p>\n<h3>The Power of Terraform and\u00a0Ansible</h3>\n<h4>Terraform: Infrastructure Provisioning Simplified</h4>\n<p>Terraform stands as a powerful infrastructure-as-code tool. It allows you to define your cloud infrastructure using a human-readable syntax. This approach streamlines the process of spinning up resources on cloud platforms like Azure. Whether it\u2019s virtual machines, networking components, or databases, Terraform\u2019s declarative approach ensures consistent provisioning across environments.</p>\n<h4>Ansible: Configuration Management Perfected</h4>\n<p>On the other hand, Ansible specializes in configuration management. It allows you to define the desired state of your servers and applications. Ansible playbooks, written in simple YAML syntax, automate the process of configuring servers, installing software, and ensuring consistency across your infrastructure. This comes in handy when you\u2019re dealing with tasks like setting up web servers or managing security configurations.</p>\n<h3>Complementary, Not Competitive</h3>\n<h4>Dispelling the Misconception</h4>\n<p>One common misconception is that Terraform and Ansible compete with each other. In reality, they are highly complementary. Terraform focuses on creating and destroying resources, while Ansible excels in configuring and maintaining those resources. This synergy ensures that your infrastructure is not just provisioned but also tailored to meet your specific requirements.</p>\n<h3>Dynamic Inventories and Pipeline Automation</h3>\n<h4>Dynamic Inventories: A Game\u00a0Changer</h4>\n<p>A remarkable feature that enhances this collaboration is the use of dynamic inventories. Instead of maintaining static inventory lists, Ansible can directly fetch information about your cloud resources from the likes of Azure using dynamic inventory plugins. This makes your playbooks flexible and adaptable to the evolving cloud landscape.</p>\n<h4>Seamless Automation with GitHub\u00a0Actions</h4>\n<p>Bringing it all together, GitHub Actions empowers you to automate your workflows. With GitHub as your source version control, you can leverage GitHub Actions to define pipelines that seamlessly integrate Terraform and Ansible. Pushing code triggers the orchestration of provisioning infrastructure and configuring it, all without manual intervention.</p>\n<h3>Embarking on Practical Cloud\u00a0Journey</h3>\n<h4>Hands-On Learning</h4>\n<p>For those eager to dive into practical knowledge, there\u2019s a treasure trove awaiting you. Inside the <a href=\"https://github.com/ishuar/terraform-ansible-azure\">GitHub repository</a>, you\u2019ll find a rich collection of code that practically demonstrates the synergy between Terraform and Ansible. Each line of code showcases how to orchestrate cloud resources and configure them seamlessly.</p>\n<p><a href=\"https://github.com/ishuar/terraform-ansible-azure\">GitHub - ishuar/terraform-ansible-azure: Terraform and Ansible: Teaming Up for Automated Azure Cloud Magic</a></p>\n<p>By immersing yourself in this repository, you\u2019re not just reading about automation; you\u2019re experiencing it firsthand. Through tinkering, testing, and exploration, you\u2019ll uncover the magic that comes to life when Terraform and Ansible work in\u00a0harmony.</p>\n<p>A glimpse of the tools and components involved is shown\u00a0below</p>\n<figure><img alt=\"architecture diagram visualising complete lifecycle of IaC using terraform\u00a0, ansible and github actions as CI platform\" src=\"https://cdn-images-1.medium.com/max/1024/1*SZqQC04atRiwZiUIC8YYOw.gif\"></figure><h4>Terraform as your spell book\u00a0\ud83d\udcd3</h4>\n<p>First thing first, please refer to the Readme file within the terraform/linux-webserver-with-loadbalancer directory for prerequisites to replicate the infrastructure in your local environment.</p>\n<blockquote>\n<strong>INFO:</strong> For the best experience open all embedded links in a new browser window/tab \ud83d\udcbb.</blockquote>\n<ul>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/local.tf\">local.tf</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/variables.tf\">variables.tf</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/dependencies.tf\">dependencies.tf</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/azure-load-balancer.tf\">azure-load-balancer.tf</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/linux-virtual-machines.tf\">linux-virtual-machines.tf</a></li>\n</ul>\n<h4>Ansible as your ancient scroll\u00a0\ud83d\udcdc</h4>\n<p>First thing first, please refer to the Readme file within the ansible directory for prerequisites to replicate the infrastructure on your local environment.</p>\n<ul><li><strong>Ansible Configuration.</strong></li></ul>\n<pre><br>##? Generate complete using: ansible-config init --disabled -t all &gt; &lt;path&gt;/ansible.cfg<br><br>[defaults]<br><br># (boolean) Set this to \"False\" if you want to avoid host key checking by the underlying tools Ansible uses to connect to the host<br>host_key_checking = False<br>force_color = True<br><br># (integer) Port to use in remote connections, when blank it will use the connection plugin default.<br>## As we have changed the default SSH port of our VMs<br>remote_port=8822<br><br>[privilege_escalation]<br><br># (boolean) Toggle to prompt for privilege escalation password.<br>become_ask_pass=False<br><br># (string) Privilege escalation method to use when `become` is enabled.<br>become_method=sudo<br><br># (string) The user your login/remote user 'becomes' when using privilege escalation, most systems will use 'root' when no user is specified.<br>become_user=root</pre>\n<ul><li><strong>Dynamic Inventory</strong></li></ul>\n<p>Refer to <a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/ansible/README.md#local-development-environment\">pre-requisites</a> for local set environment set\u00a0up.</p>\n<pre>---<br>plugin: azure_rm<br><br>include_vm_resource_groups:<br>  - ansible-vm-resources<br><br>auth_source: auto<br>conditional_groups:<br>  # since this will be true for every host, every host sourced from this inventory plugin config will be in the<br>  # group 'all_the_hosts'<br>  all_the_hosts: true<br><br># places hosts in dynamically-created groups based on a variable value.<br>keyed_groups:<br>  # places each host in a group named 'tag_(tag name)_(tag value)' for each tag on a VM.<br>  # - prefix: tag<br>  #   key: tags<br>  # places each host in a group named 'azure_loc_(location name)', depending on the VM's location<br>  - prefix: azure_loc<br>    key: location<br>  # places host in a group named 'some_tag_X' using the value of the 'sometag' tag on a VM as X, and defaulting to the<br>  # value 'none' (eg, the group 'some_tag_none') if the 'sometag' tag is not defined for a VM.<br>  - prefix: role<br>    key: tags.role | default('none')</pre>\n<ul>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/tree/main/ansible/roles\"><strong>Ansible Roles\u00a0Involved</strong></a></li>\n<li><strong>Ansible Playbook</strong></li>\n</ul>\n<pre>---<br>- name: Set up Nginx Webserver on Ubuntu machine<br>  gather_facts: true<br>  remote_user: adminuser<br>  hosts: \"{{ dynamic_hosts }}\"<br>  become: true<br>  connection: ssh<br>  pre_tasks: []<br>  vars:<br>    dynamic_hosts: role_slave_webservers<br><br>  roles:<br>    - role: azure_vm_ufw<br>      when: enable_firewall | bool<br>    - role: nginx_webserver</pre>\n<h4>Realm of GitHub Actions\u00a0\ud83e\ude90</h4>\n<p>The concept of <a href=\"https://docs.github.com/en/actions/using-workflows/reusing-workflows\">Github reusable workflows</a> is utilized in the repository, which means creating a workflow one time and then re-using it accordingly.</p>\n<p><strong>Reusable Workflows</strong></p>\n<ul>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/.github/workflows/terraform-infra-set-up.yaml\">terraform-infra-set-up.yaml</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/.github/workflows/ansible-set-up.yaml\">ansible-set-up.yaml</a></li>\n</ul>\n<p><strong>Deployment and Configuration Workflows</strong></p>\n<ul><li>webservers-infra-terraform.yaml</li></ul>\n<pre>name: \"Create Webservers Infrastructure\"<br>on:<br>  workflow_dispatch:<br>    inputs:<br>      terraform-version:<br>        type: number<br>        required: false<br>        default: 1.5.4<br>        description: The terraform version used for the github action.<br><br>      cache-hash-file:<br>        type: string<br>        required: false<br>        default: '/providers.tf'<br>        description: The file used to create common hash cache naming.<br>  push:<br>      branches:<br>        - main<br>      paths:<br>      - \"terraform/**\"<br>      - \".github/workflows/terraform-infra-set-up.yaml\"<br>      - \".github/workflows/webservers-infra-terraform.yaml\"<br><br>  pull_request:<br>    paths:<br>    - \"terraform/**\"<br>    - \".github/workflows/terraform-infra-set-up.yaml\"<br>    - \".github/workflows/webservers-infra-terraform.yaml\"<br><br>concurrency:<br>  group: terraform-webservers<br><br>jobs:<br>  webserversInfra:<br>    name: Create infrastructure for webservers<br>    uses: ./.github/workflows/terraform-infra-set-up.yaml<br>    with:<br>      terraform-dir: \"terraform/linux-webserver-with-loadbalancer\"<br>      terraform-version: ${{ inputs.terraform-version != '' &amp;&amp; inputs.terraform-version || vars.TERRAFORM_VERSION }}<br>    secrets: inherit</pre>\n<ul><li>webservers-config-ansible.yaml</li></ul>\n<pre>name: \"Configure Nginx Webservers in Ubuntu via Ansible\"<br>on:<br>  workflow_dispatch:<br>  push:<br>    branches:<br>      - main<br>    ## in Case push to main by codeowners<br>    paths:<br>    - \"ansible/**\"<br>    - \".github/workflows/set-up-ubuntu-nginx-webserver.yaml\"<br>    - \".github/workflows/ansible-set-up.yaml\"<br><br>  pull_request:<br>    paths:<br>    - \"ansible/**\"<br>    - \".github/workflows/set-up-ubuntu-nginx-webserver.yaml\"<br>    - \".github/workflows/ansible-set-up.yaml\"<br><br>concurrency:<br>  group: ansible-webservers<br><br>jobs:<br>  webserversConfig:<br>    name: Configure Nginx webservers<br>    uses: ./.github/workflows/ansible-set-up.yaml<br>    with:<br>      playbook: set-up-ubuntu-nginx-webserver.yaml<br>      terraform-output-directory: terraform/linux-webserver-with-loadbalancer<br>      nsg-ssh-port: 8822<br>    secrets:<br>      ssh-private-key: ${{ secrets.PASSWORDLESS_SSH_PRIVATE_KEY }}<br>      AZURE_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}<br>      AZURE_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}<br>      AZURE_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}<br>      AZURE_SUBSCRIPTION_ID: ${{ vars.ARM_SUBSCRIPTION_ID }}</pre>\n<h3>Wrapping Up</h3>\n<p>Terraform and Ansible are more than just tools; they represent a collaborative approach to cloud automation. By using Terraform for infrastructure provisioning and Ansible for configuration management, you unlock a potent synergy that ensures your cloud environment is both robust and adaptable. Add dynamic inventories and GitHub Actions into the mix, and you have a recipe for automated cloud magic that simplifies and streamlines your operations.</p>\n<p>Happy automating!</p>\n<h3>Thank You\u00a0\ud83d\ude4f</h3>\n<p>A heartfelt thank you and gratitude for the time you\u2019ve spent reading the article. I hope I was able to ignite your curiosity and guide you through the realm of Terraform, Ansible, and cloud\u00a0magic.</p>\n<p><strong>Your thoughts\u00a0matter!</strong></p>\n<p>If this journey sparked ideas or questions, I\u2019d love to hear from you. Share your feedback and suggestions via <a href=\"https://github.com/ishuar/terraform-ansible-azure/issues\">GitHub Issue</a> or even a magical star \u2b50\ufe0f for the project on\u00a0GitHub.</p>\n<p><em>Stay tuned for more tech insights and connect on </em><a href=\"https://www.linkedin.com/in/ishuar/\"><em>LinkedIn</em></a><em> to get the latest\u00a0updates.</em></p>\n<p><a href=\"https://github.com/ishuar\">ishuar - Overview</a></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=70c6285a3dc1\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*SZqQC04atRiwZiUIC8YYOw.gif\"></figure><h3>TL;DR</h3>\n<p>In the world of cloud automation, Terraform and Ansible form a seamless partnership. Terraform constructs infrastructure, while Ansible configures it. Leveraging dynamic inventories and GitHub Actions, the process gains efficiency.</p>\n<p>Explore my <a href=\"https://github.com/ishuar/terraform-ansible-azure\">GitHub repository</a> for hands-on experience. Delve into Terraform\u2019s provisioning, Ansible\u2019s management, and GitHub\u2019s orchestration.</p>\n<p><em>Unlock cloud automation with Terraform, Ansible, and GitHub\u2019s\u00a0synergy.</em></p>\n<h3>Introduction</h3>\n<p>In the dynamic world of cloud computing, provisioning infrastructure, and managing configurations are essential tasks. This is where Terraform and Ansible come into play, acting as a dynamic duo that enables you to orchestrate automated cloud\u00a0magic.</p>\n<h3>The Power of Terraform and\u00a0Ansible</h3>\n<h4>Terraform: Infrastructure Provisioning Simplified</h4>\n<p>Terraform stands as a powerful infrastructure-as-code tool. It allows you to define your cloud infrastructure using a human-readable syntax. This approach streamlines the process of spinning up resources on cloud platforms like Azure. Whether it\u2019s virtual machines, networking components, or databases, Terraform\u2019s declarative approach ensures consistent provisioning across environments.</p>\n<h4>Ansible: Configuration Management Perfected</h4>\n<p>On the other hand, Ansible specializes in configuration management. It allows you to define the desired state of your servers and applications. Ansible playbooks, written in simple YAML syntax, automate the process of configuring servers, installing software, and ensuring consistency across your infrastructure. This comes in handy when you\u2019re dealing with tasks like setting up web servers or managing security configurations.</p>\n<h3>Complementary, Not Competitive</h3>\n<h4>Dispelling the Misconception</h4>\n<p>One common misconception is that Terraform and Ansible compete with each other. In reality, they are highly complementary. Terraform focuses on creating and destroying resources, while Ansible excels in configuring and maintaining those resources. This synergy ensures that your infrastructure is not just provisioned but also tailored to meet your specific requirements.</p>\n<h3>Dynamic Inventories and Pipeline Automation</h3>\n<h4>Dynamic Inventories: A Game\u00a0Changer</h4>\n<p>A remarkable feature that enhances this collaboration is the use of dynamic inventories. Instead of maintaining static inventory lists, Ansible can directly fetch information about your cloud resources from the likes of Azure using dynamic inventory plugins. This makes your playbooks flexible and adaptable to the evolving cloud landscape.</p>\n<h4>Seamless Automation with GitHub\u00a0Actions</h4>\n<p>Bringing it all together, GitHub Actions empowers you to automate your workflows. With GitHub as your source version control, you can leverage GitHub Actions to define pipelines that seamlessly integrate Terraform and Ansible. Pushing code triggers the orchestration of provisioning infrastructure and configuring it, all without manual intervention.</p>\n<h3>Embarking on Practical Cloud\u00a0Journey</h3>\n<h4>Hands-On Learning</h4>\n<p>For those eager to dive into practical knowledge, there\u2019s a treasure trove awaiting you. Inside the <a href=\"https://github.com/ishuar/terraform-ansible-azure\">GitHub repository</a>, you\u2019ll find a rich collection of code that practically demonstrates the synergy between Terraform and Ansible. Each line of code showcases how to orchestrate cloud resources and configure them seamlessly.</p>\n<p><a href=\"https://github.com/ishuar/terraform-ansible-azure\">GitHub - ishuar/terraform-ansible-azure: Terraform and Ansible: Teaming Up for Automated Azure Cloud Magic</a></p>\n<p>By immersing yourself in this repository, you\u2019re not just reading about automation; you\u2019re experiencing it firsthand. Through tinkering, testing, and exploration, you\u2019ll uncover the magic that comes to life when Terraform and Ansible work in\u00a0harmony.</p>\n<p>A glimpse of the tools and components involved is shown\u00a0below</p>\n<figure><img alt=\"architecture diagram visualising complete lifecycle of IaC using terraform\u00a0, ansible and github actions as CI platform\" src=\"https://cdn-images-1.medium.com/max/1024/1*SZqQC04atRiwZiUIC8YYOw.gif\"></figure><h4>Terraform as your spell book\u00a0\ud83d\udcd3</h4>\n<p>First thing first, please refer to the Readme file within the terraform/linux-webserver-with-loadbalancer directory for prerequisites to replicate the infrastructure in your local environment.</p>\n<blockquote>\n<strong>INFO:</strong> For the best experience open all embedded links in a new browser window/tab \ud83d\udcbb.</blockquote>\n<ul>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/local.tf\">local.tf</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/variables.tf\">variables.tf</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/dependencies.tf\">dependencies.tf</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/azure-load-balancer.tf\">azure-load-balancer.tf</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/terraform/linux-webserver-with-loadbalancer/linux-virtual-machines.tf\">linux-virtual-machines.tf</a></li>\n</ul>\n<h4>Ansible as your ancient scroll\u00a0\ud83d\udcdc</h4>\n<p>First thing first, please refer to the Readme file within the ansible directory for prerequisites to replicate the infrastructure on your local environment.</p>\n<ul><li><strong>Ansible Configuration.</strong></li></ul>\n<pre><br>##? Generate complete using: ansible-config init --disabled -t all &gt; &lt;path&gt;/ansible.cfg<br><br>[defaults]<br><br># (boolean) Set this to \"False\" if you want to avoid host key checking by the underlying tools Ansible uses to connect to the host<br>host_key_checking = False<br>force_color = True<br><br># (integer) Port to use in remote connections, when blank it will use the connection plugin default.<br>## As we have changed the default SSH port of our VMs<br>remote_port=8822<br><br>[privilege_escalation]<br><br># (boolean) Toggle to prompt for privilege escalation password.<br>become_ask_pass=False<br><br># (string) Privilege escalation method to use when `become` is enabled.<br>become_method=sudo<br><br># (string) The user your login/remote user 'becomes' when using privilege escalation, most systems will use 'root' when no user is specified.<br>become_user=root</pre>\n<ul><li><strong>Dynamic Inventory</strong></li></ul>\n<p>Refer to <a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/ansible/README.md#local-development-environment\">pre-requisites</a> for local set environment set\u00a0up.</p>\n<pre>---<br>plugin: azure_rm<br><br>include_vm_resource_groups:<br>  - ansible-vm-resources<br><br>auth_source: auto<br>conditional_groups:<br>  # since this will be true for every host, every host sourced from this inventory plugin config will be in the<br>  # group 'all_the_hosts'<br>  all_the_hosts: true<br><br># places hosts in dynamically-created groups based on a variable value.<br>keyed_groups:<br>  # places each host in a group named 'tag_(tag name)_(tag value)' for each tag on a VM.<br>  # - prefix: tag<br>  #   key: tags<br>  # places each host in a group named 'azure_loc_(location name)', depending on the VM's location<br>  - prefix: azure_loc<br>    key: location<br>  # places host in a group named 'some_tag_X' using the value of the 'sometag' tag on a VM as X, and defaulting to the<br>  # value 'none' (eg, the group 'some_tag_none') if the 'sometag' tag is not defined for a VM.<br>  - prefix: role<br>    key: tags.role | default('none')</pre>\n<ul>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/tree/main/ansible/roles\"><strong>Ansible Roles\u00a0Involved</strong></a></li>\n<li><strong>Ansible Playbook</strong></li>\n</ul>\n<pre>---<br>- name: Set up Nginx Webserver on Ubuntu machine<br>  gather_facts: true<br>  remote_user: adminuser<br>  hosts: \"{{ dynamic_hosts }}\"<br>  become: true<br>  connection: ssh<br>  pre_tasks: []<br>  vars:<br>    dynamic_hosts: role_slave_webservers<br><br>  roles:<br>    - role: azure_vm_ufw<br>      when: enable_firewall | bool<br>    - role: nginx_webserver</pre>\n<h4>Realm of GitHub Actions\u00a0\ud83e\ude90</h4>\n<p>The concept of <a href=\"https://docs.github.com/en/actions/using-workflows/reusing-workflows\">Github reusable workflows</a> is utilized in the repository, which means creating a workflow one time and then re-using it accordingly.</p>\n<p><strong>Reusable Workflows</strong></p>\n<ul>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/.github/workflows/terraform-infra-set-up.yaml\">terraform-infra-set-up.yaml</a></li>\n<li><a href=\"https://github.com/ishuar/terraform-ansible-azure/blob/main/.github/workflows/ansible-set-up.yaml\">ansible-set-up.yaml</a></li>\n</ul>\n<p><strong>Deployment and Configuration Workflows</strong></p>\n<ul><li>webservers-infra-terraform.yaml</li></ul>\n<pre>name: \"Create Webservers Infrastructure\"<br>on:<br>  workflow_dispatch:<br>    inputs:<br>      terraform-version:<br>        type: number<br>        required: false<br>        default: 1.5.4<br>        description: The terraform version used for the github action.<br><br>      cache-hash-file:<br>        type: string<br>        required: false<br>        default: '/providers.tf'<br>        description: The file used to create common hash cache naming.<br>  push:<br>      branches:<br>        - main<br>      paths:<br>      - \"terraform/**\"<br>      - \".github/workflows/terraform-infra-set-up.yaml\"<br>      - \".github/workflows/webservers-infra-terraform.yaml\"<br><br>  pull_request:<br>    paths:<br>    - \"terraform/**\"<br>    - \".github/workflows/terraform-infra-set-up.yaml\"<br>    - \".github/workflows/webservers-infra-terraform.yaml\"<br><br>concurrency:<br>  group: terraform-webservers<br><br>jobs:<br>  webserversInfra:<br>    name: Create infrastructure for webservers<br>    uses: ./.github/workflows/terraform-infra-set-up.yaml<br>    with:<br>      terraform-dir: \"terraform/linux-webserver-with-loadbalancer\"<br>      terraform-version: ${{ inputs.terraform-version != '' &amp;&amp; inputs.terraform-version || vars.TERRAFORM_VERSION }}<br>    secrets: inherit</pre>\n<ul><li>webservers-config-ansible.yaml</li></ul>\n<pre>name: \"Configure Nginx Webservers in Ubuntu via Ansible\"<br>on:<br>  workflow_dispatch:<br>  push:<br>    branches:<br>      - main<br>    ## in Case push to main by codeowners<br>    paths:<br>    - \"ansible/**\"<br>    - \".github/workflows/set-up-ubuntu-nginx-webserver.yaml\"<br>    - \".github/workflows/ansible-set-up.yaml\"<br><br>  pull_request:<br>    paths:<br>    - \"ansible/**\"<br>    - \".github/workflows/set-up-ubuntu-nginx-webserver.yaml\"<br>    - \".github/workflows/ansible-set-up.yaml\"<br><br>concurrency:<br>  group: ansible-webservers<br><br>jobs:<br>  webserversConfig:<br>    name: Configure Nginx webservers<br>    uses: ./.github/workflows/ansible-set-up.yaml<br>    with:<br>      playbook: set-up-ubuntu-nginx-webserver.yaml<br>      terraform-output-directory: terraform/linux-webserver-with-loadbalancer<br>      nsg-ssh-port: 8822<br>    secrets:<br>      ssh-private-key: ${{ secrets.PASSWORDLESS_SSH_PRIVATE_KEY }}<br>      AZURE_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}<br>      AZURE_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}<br>      AZURE_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}<br>      AZURE_SUBSCRIPTION_ID: ${{ vars.ARM_SUBSCRIPTION_ID }}</pre>\n<h3>Wrapping Up</h3>\n<p>Terraform and Ansible are more than just tools; they represent a collaborative approach to cloud automation. By using Terraform for infrastructure provisioning and Ansible for configuration management, you unlock a potent synergy that ensures your cloud environment is both robust and adaptable. Add dynamic inventories and GitHub Actions into the mix, and you have a recipe for automated cloud magic that simplifies and streamlines your operations.</p>\n<p>Happy automating!</p>\n<h3>Thank You\u00a0\ud83d\ude4f</h3>\n<p>A heartfelt thank you and gratitude for the time you\u2019ve spent reading the article. I hope I was able to ignite your curiosity and guide you through the realm of Terraform, Ansible, and cloud\u00a0magic.</p>\n<p><strong>Your thoughts\u00a0matter!</strong></p>\n<p>If this journey sparked ideas or questions, I\u2019d love to hear from you. Share your feedback and suggestions via <a href=\"https://github.com/ishuar/terraform-ansible-azure/issues\">GitHub Issue</a> or even a magical star \u2b50\ufe0f for the project on\u00a0GitHub.</p>\n<p><em>Stay tuned for more tech insights and connect on </em><a href=\"https://www.linkedin.com/in/ishuar/\"><em>LinkedIn</em></a><em> to get the latest\u00a0updates.</em></p>\n<p><a href=\"https://github.com/ishuar\">ishuar - Overview</a></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=70c6285a3dc1\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["devops","infrastructure-as-code","terraform","ansible","github-actions"]},{"title":"Expanding Persistent Volumes for Statefulsets in Kubernetes","pubDate":"2023-11-23 12:56:12","link":"https://ishuar.medium.com/expanding-persistent-volumes-for-statefulsets-in-kubernetes-ecd7cf75b754?source=rss-6962bfed9f3------2","guid":"https://medium.com/p/ecd7cf75b754","author":"Ishan Sharma","thumbnail":"","description":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*zTlqffP7_Fd9nHPJ\"><figcaption>Photo by <a href=\"https://unsplash.com/@growtika?utm_source=medium&amp;utm_medium=referral\">Growtika</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><h3><strong>Expanding Persistent Volumes for StatefulSets in Kubernetes</strong></h3>\n<p>Expanding volumes in Kubernetes clusters is a routine maintenance activity and seemingly straightforward\u200a\u2014\u200aor so I thought! Recently, a unique challenge arose when there was a request to increase the storage size for a Stateful Application running in a Kubernetes cluster.</p>\n<p>Let\u2019s jump into the story to share the real-world experience of this\u00a0request.</p>\n<h4><strong>Problem Statement</strong></h4>\n<p>In the realm of Kubernetes clusters, a statefulset application thrived. Its popularity soared to the extent that it demanded more storage than the currently attached volume could provide. The team, recognizing the need to meet this demand, set out to expand the storage of the persistent volume connected to the statefulset.<em> However, quickly realized that this was easier said than\u00a0done.</em></p>\n<p>As<a href=\"https://kubernetes.io/blog/2022/05/05/volume-expansion-ga/\"> Kubernetes 1.24</a> supports volume expansion, Just like anyone who had the first encounter with this task, I anticipated that it was as simple as increasing the spec.volumeClaimTemplates.spec.resources.requests.storage in the statefulset application. <strong>**But**</strong> It was not\u00a0!!</p>\n<p>Contrary to initial expectations, modifying the spec.volumeClaimTemplates.spec.resources.requests.storage alone does not trigger the expansion of volumes attached to statefulsets. Manual intervention is necessary to navigate this intricate landscape. Let\u2019s learn how can we achieve it in this\u00a0article.</p>\n<h4><strong>Prerequisites For Persistent Volume Expansion</strong></h4>\n<ul>\n<li>The underlying provider and CSI driver for the persistent volume must support volume expansion. You should refer to the documentation of your CSI driver to check the capability. (Managed Kubernetes with their inbuilt CSI driver supports this natively and the feature volume expansion is also\u00a0enabled)</li>\n<li>Volume expansion must be enabled on the respective storage class used by the persistent volume. This can be checked using the below\u00a0command:</li>\n</ul>\n<pre>## Output in Name of storageclass with support to ALLOWVOLUMEEXPANSION<br>$ kubectl get storageclass -o custom-columns=NAME:.metadata.name,ALLOWVOLUMEEXPANSION:.allowVolumeExpansion</pre>\n<p>Output from the above command will look something like\u00a0this:</p>\n<pre>NAME                    ALLOWVOLUMEEXPANSION<br>azurefile               true<br>azurefile-csi           true<br>azurefile-csi-premium   true<br>azurefile-premium       true<br>default                 true<br>managed                 true<br>managed-csi             true<br>managed-csi-premium     true<br>managed-premium         true</pre>\n<h4><strong>Step-by-Step Guide With\u00a0Example.</strong></h4>\n<p>To make it more practical, I will use the Alertmanager application, which is installed with the <a href=\"https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack\">kube-prometheus-stack</a> helm\u00a0chart.</p>\n<p><strong>Reproduce the\u00a0problem</strong></p>\n<ul><li>Installation of helm\u00a0chart.</li></ul>\n<pre>$ helm repo add prometheus-community https://prometheus-community.github.io/helm-charts<br>$ helm repo update<br>$ helm upgrade --install kube-prom-stack prometheus-community/kube-prometheus-stack --namespace kube-prom-stack --create-namespace --values custom-values.yaml<br>Release \"kube-prom-stack\" does not exist. Installing it now.<br>NAME: kube-prom-stack<br>LAST DEPLOYED: Thu Nov 23 10:42:39 2023<br>NAMESPACE: kube-prom-stack<br>STATUS: deployed<br>REVISION: 1<br>NOTES:<br>kube-prometheus-stack has been installed. Check its status by running:<br>  kubectl --namespace kube-prom-stack get pods -l \"release=kube-prom-stack\"<br><br>Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create &amp; configure Alertmanager and Prometheus instances using the Operator.<br></pre>\n<blockquote>\n<strong>Info:</strong> Application details are out of the scope of this\u00a0article.</blockquote>\n<ul><li>custom-values.yaml</li></ul>\n<pre>alertmanager:<br>  ingress:<br>    enabled: false<br><br>  podDisruptionBudget:<br>    enabled: false<br><br>  alertmanagerSpec:<br>    storage:<br>      volumeClaimTemplate:<br>        spec:<br>          accessModes: [\"ReadWriteOnce\"]<br>          resources:<br>            requests:<br>              storage: 2Gi</pre>\n<p>Once the installation is complete, we can list the statefulsets.</p>\n<blockquote>\n<strong>Info:</strong> kube-prom-stack namespace is set as the default namespace.</blockquote>\n<pre>$ kubectl get statefulsets<br>NAME                                                   READY   AGE<br>alertmanager-kube-prom-stack-kube-prome-alertmanager   1/1     11m<br>prometheus-kube-prom-stack-kube-prome-prometheus       1/1     11m</pre>\n<ul><li>Check the details of the Persistent volume claim created by the volumeClaimTemplates specification of the statefulset to verify if the correct values are\u00a0applied.</li></ul>\n<pre>## Get the pvc name from the statefulset volumeClaimTemplate<br>$ kubectl get sts alertmanager-kube-prom-stack-kube-prome-alertmanager -o jsonpath='{.spec.volumeClaimTemplates[0].metadata.name}' ; echo \"\"<br>alertmanager-kube-prom-stack-kube-prome-alertmanager-db<br><br>## Get the pvc size request from the statefulset volumeClaimTemplate<br>$ kubectl get sts alertmanager-kube-prom-stack-kube-prome-alertmanager -o jsonpath='{.spec.volumeClaimTemplates[0].spec.resources}' | jq<br>{<br>  \"requests\": {<br>    \"storage\": \"2Gi\"<br>  }<br>}<br><br>## Verify the size of the pvc got from the statefulset volumeClaimTemplate<br>$ kubectl get pvc alertmanager-kube-prom-stack-kube-prome-alertmanager-db-alertmanager-kube-prom-stack-kube-prome-alertmanager-0 -o jsonpath='{.spec.resources.requests}' | jq<br>{<br>  \"storage\": \"2Gi\"<br>}</pre>\n<p>Storage is 2Gi which seems to be as per our provided custom-values.yaml \u2705</p>\n<ul>\n<li>Extend the persistent volume claim storage request viacustom-values.yaml.</li>\n<li>Modified custom-values.yaml</li>\n</ul>\n<pre>alertmanager:<br>  ingress:<br>    enabled: false<br><br>  podDisruptionBudget:<br>    enabled: false<br><br>  alertmanagerSpec:<br>    storage:<br>      volumeClaimTemplate:<br>        spec:<br>          accessModes: [\"ReadWriteOnce\"]<br>          resources:<br>            requests:<br>              storage: 5Gi ## Increased ##</pre>\n<p>The size is updated to 5Gi\u00a0, will apply the new values and monitor the\u00a0changes.</p>\n<ul><li>Helm upgrade with new\u00a0values.</li></ul>\n<pre>$ helm upgrade --install kube-prom-stack prometheus-community/kube-prometheus-stack --namespace kube-prom-stack --values custom-values.yaml<br>Release \"kube-prom-stack\" has been upgraded. Happy Helming!<br>NAME: kube-prom-stack<br>LAST DEPLOYED: Thu Nov 23 10:55:25 2023<br>NAMESPACE: kube-prom-stack<br>STATUS: deployed<br>REVISION: 2<br>NOTES:<br>kube-prometheus-stack has been installed. Check its status by running:<br>  kubectl --namespace kube-prom-stack get pods -l \"release=kube-prom-stack\"<br><br>Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create &amp; configure Alertmanager and Prometheus instances using the Operator.</pre>\n<ul><li>Check the details of the Persistent volume claim after updating the\u00a0size.</li></ul>\n<pre>## Get the pvc name from the statefulset volumeClaimTemplate<br>$ kubectl get sts alertmanager-kube-prom-stack-kube-prome-alertmanager -o jsonpath='{.spec.volumeClaimTemplates[0].metadata.name}' ; echo \"\"<br>alertmanager-kube-prom-stack-kube-prome-alertmanager-db<br><br>## Get the pvc size request from the statefulset volumeClaimTemplate (UPDATED)<br>$ kubectl get sts alertmanager-kube-prom-stack-kube-prome-alertmanager -o jsonpath='{.spec.volumeClaimTemplates[0].spec.resources}' | jq<br>{<br>  \"requests\": {<br>    \"storage\": \"5Gi\"<br>  }<br>}<br><br>## Verify the size of the pvc got from the statefulset volumeClaimTemplate (NOT-UPDATED)<br>$ kubectl get pvc alertmanager-kube-prom-stack-kube-prome-alertmanager-db-alertmanager-kube-prom-stack-kube-prome-alertmanager-0 -o jsonpath='{.spec.resources.requests}' | jq<br>{<br>  \"storage\": \"2Gi\"<br>}</pre>\n<p>Even though the volumeClaimTemplate of statefulset(alertmanager) is updated the persistent volume claim is using the old size 2Gi.\u00a0\u274c</p>\n<h4>Solution</h4>\n<p>The following steps are required to increase the size from 2Gito\u00a05Gi</p>\n<ul><li>\n<strong>STEP 1:</strong> In this case, the statefulset is managed via the operator and hence needs to be paused as well on the custom resource alertmanager</li></ul>\n<pre>## Get the name of alertmanager resource<br>$ kubectl get alertmanager<br>NAME                                      VERSION   REPLICAS   READY   RECONCILED   AVAILABLE   AGE<br>kube-prom-stack-kube-prome-alertmanager   v0.26.0   1          1       True         True        61m</pre>\n<pre>## Patch the resource , so that operator does not recreates it.<br>$ kubectl patch alertmanager/kube-prom-stack-kube-prome-alertmanager  --patch '{\"spec\": {\"paused\": true, \"storage\": {\"volumeClaimTemplate\": {\"spec\": {\"resources\": {\"requests\": {\"storage\":\"5Gi\"}}}}}}}' --type merge<br>alertmanager.monitoring.coreos.com/kube-prom-stack-kube-prome-alertmanager patched</pre>\n<ul><li>\n<strong>STEP 2:</strong> Patch the persistent volume claims associated with the statefulset.</li></ul>\n<pre>for p in $(kubectl get pvc -l alertmanager=kube-prom-stack-kube-prome-alertmanager -o jsonpath='{range .items[*]}{.metadata.name} {end}'); do \\<br>  kubectl patch pvc/${p} --patch '{\"spec\": {\"resources\": {\"requests\": {\"storage\":\"5Gi\"}}}}'; \\<br>done</pre>\n<ul><li>\n<strong>STEP 3:</strong> The final step is to delete the statefulset with the orphan strategy.</li></ul>\n<pre>$ kubectl delete sts alertmanager-kube-prom-stack-kube-prome-alertmanager --cascade=orphan</pre>\n<p><em>To verify if the PVC is extended.</em></p>\n<pre>## PVC is updated<br>$ kubectl get pvc alertmanager-kube-prom-stack-kube-prome-alertmanager-db-alertmanager-kube-prom-stack-kube-prome-alertmanager-0 -o jsonpath='{.spec.resources.requests}' | jq<br>{<br>  \"storage\": \"5Gi\"<br>}</pre>\n<p>By passing --cascade=orphan to kubectl delete, the Pods managed by the StatefulSet are left behind even after the StatefulSet object itself is\u00a0deleted.</p>\n<ul><li>\n<strong>STEP 4:</strong> Resume the operator to take control of the alertmanager provisioning. This step is valid in statefulsets managed via operators only.</li></ul>\n<pre>$ kubectl patch alertmanager/kube-prom-stack-kube-prome-alertmanager --patch '{\"spec\": {\"paused\": false}}' --type merge</pre>\n<h3>Conclusion</h3>\n<p>In Summary following steps need to be followed in the respective order to expand the persistent volume on statefulsets.</p>\n<ol>\n<li>Patch the statefulset with the required(expanded) volumeClaimTemplates configuration.</li>\n<li>Patch the persistent volume claims with the required(expanded) size configuration associated with the statefulset.</li>\n<li>Delete the statefulset with cascade=orphan strategy.</li>\n</ol>\n<p>And that concludes our exploration into the dynamic world of scaling storage for stateful applications in Kubernetes.</p>\n<p>Expanding the persistent volumes in statefulsets is a well-known restriction and is been tracked in the <a href=\"https://github.com/kubernetes/enhancements/issues/661\">Support Volume Expansion Through StatefulSets</a> and <a href=\"https://github.com/kubernetes/kubernetes/issues/68737\">StatefulSet: support resize pvc storage in K8s v1.11</a> GitHub issues in official Kubernetes repositories.</p>\n<h3>Acknowledgments</h3>\n<p>Thank you for embarking on this Kubernetes adventure with me. Scaling storage in Kubernetes can be complex, but you\u2019ve gained valuable insights to navigate this terrain. May your clusters be resilient, and your applications thrive. Happy reading, and until our next exploration!</p>\n<h3>Helpful Links</h3>\n<ul>\n<li><a href=\"https://kubernetes.io/blog/2022/05/05/volume-expansion-ga/\">Kubernetes 1.24: Volume Expansion Now A Stable\u00a0Feature</a></li>\n<li><a href=\"https://prometheus-operator.dev/docs/operator/storage/#resizing-volumes\">Resizing Prometheus Operator\u00a0Volumes</a></li>\n<li><a href=\"https://github.com/kubernetes/kubernetes/issues/68737\">StatefulSet: support resize pvc storage in K8s\u00a0v1.11</a></li>\n<li><a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#expanding-persistent-volumes-claims\">Expanding Persistent Volumes\u00a0Claims</a></li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ecd7cf75b754\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*zTlqffP7_Fd9nHPJ\"><figcaption>Photo by <a href=\"https://unsplash.com/@growtika?utm_source=medium&amp;utm_medium=referral\">Growtika</a> on\u00a0<a href=\"https://unsplash.com/?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><h3><strong>Expanding Persistent Volumes for StatefulSets in Kubernetes</strong></h3>\n<p>Expanding volumes in Kubernetes clusters is a routine maintenance activity and seemingly straightforward\u200a\u2014\u200aor so I thought! Recently, a unique challenge arose when there was a request to increase the storage size for a Stateful Application running in a Kubernetes cluster.</p>\n<p>Let\u2019s jump into the story to share the real-world experience of this\u00a0request.</p>\n<h4><strong>Problem Statement</strong></h4>\n<p>In the realm of Kubernetes clusters, a statefulset application thrived. Its popularity soared to the extent that it demanded more storage than the currently attached volume could provide. The team, recognizing the need to meet this demand, set out to expand the storage of the persistent volume connected to the statefulset.<em> However, quickly realized that this was easier said than\u00a0done.</em></p>\n<p>As<a href=\"https://kubernetes.io/blog/2022/05/05/volume-expansion-ga/\"> Kubernetes 1.24</a> supports volume expansion, Just like anyone who had the first encounter with this task, I anticipated that it was as simple as increasing the spec.volumeClaimTemplates.spec.resources.requests.storage in the statefulset application. <strong>**But**</strong> It was not\u00a0!!</p>\n<p>Contrary to initial expectations, modifying the spec.volumeClaimTemplates.spec.resources.requests.storage alone does not trigger the expansion of volumes attached to statefulsets. Manual intervention is necessary to navigate this intricate landscape. Let\u2019s learn how can we achieve it in this\u00a0article.</p>\n<h4><strong>Prerequisites For Persistent Volume Expansion</strong></h4>\n<ul>\n<li>The underlying provider and CSI driver for the persistent volume must support volume expansion. You should refer to the documentation of your CSI driver to check the capability. (Managed Kubernetes with their inbuilt CSI driver supports this natively and the feature volume expansion is also\u00a0enabled)</li>\n<li>Volume expansion must be enabled on the respective storage class used by the persistent volume. This can be checked using the below\u00a0command:</li>\n</ul>\n<pre>## Output in Name of storageclass with support to ALLOWVOLUMEEXPANSION<br>$ kubectl get storageclass -o custom-columns=NAME:.metadata.name,ALLOWVOLUMEEXPANSION:.allowVolumeExpansion</pre>\n<p>Output from the above command will look something like\u00a0this:</p>\n<pre>NAME                    ALLOWVOLUMEEXPANSION<br>azurefile               true<br>azurefile-csi           true<br>azurefile-csi-premium   true<br>azurefile-premium       true<br>default                 true<br>managed                 true<br>managed-csi             true<br>managed-csi-premium     true<br>managed-premium         true</pre>\n<h4><strong>Step-by-Step Guide With\u00a0Example.</strong></h4>\n<p>To make it more practical, I will use the Alertmanager application, which is installed with the <a href=\"https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack\">kube-prometheus-stack</a> helm\u00a0chart.</p>\n<p><strong>Reproduce the\u00a0problem</strong></p>\n<ul><li>Installation of helm\u00a0chart.</li></ul>\n<pre>$ helm repo add prometheus-community https://prometheus-community.github.io/helm-charts<br>$ helm repo update<br>$ helm upgrade --install kube-prom-stack prometheus-community/kube-prometheus-stack --namespace kube-prom-stack --create-namespace --values custom-values.yaml<br>Release \"kube-prom-stack\" does not exist. Installing it now.<br>NAME: kube-prom-stack<br>LAST DEPLOYED: Thu Nov 23 10:42:39 2023<br>NAMESPACE: kube-prom-stack<br>STATUS: deployed<br>REVISION: 1<br>NOTES:<br>kube-prometheus-stack has been installed. Check its status by running:<br>  kubectl --namespace kube-prom-stack get pods -l \"release=kube-prom-stack\"<br><br>Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create &amp; configure Alertmanager and Prometheus instances using the Operator.<br></pre>\n<blockquote>\n<strong>Info:</strong> Application details are out of the scope of this\u00a0article.</blockquote>\n<ul><li>custom-values.yaml</li></ul>\n<pre>alertmanager:<br>  ingress:<br>    enabled: false<br><br>  podDisruptionBudget:<br>    enabled: false<br><br>  alertmanagerSpec:<br>    storage:<br>      volumeClaimTemplate:<br>        spec:<br>          accessModes: [\"ReadWriteOnce\"]<br>          resources:<br>            requests:<br>              storage: 2Gi</pre>\n<p>Once the installation is complete, we can list the statefulsets.</p>\n<blockquote>\n<strong>Info:</strong> kube-prom-stack namespace is set as the default namespace.</blockquote>\n<pre>$ kubectl get statefulsets<br>NAME                                                   READY   AGE<br>alertmanager-kube-prom-stack-kube-prome-alertmanager   1/1     11m<br>prometheus-kube-prom-stack-kube-prome-prometheus       1/1     11m</pre>\n<ul><li>Check the details of the Persistent volume claim created by the volumeClaimTemplates specification of the statefulset to verify if the correct values are\u00a0applied.</li></ul>\n<pre>## Get the pvc name from the statefulset volumeClaimTemplate<br>$ kubectl get sts alertmanager-kube-prom-stack-kube-prome-alertmanager -o jsonpath='{.spec.volumeClaimTemplates[0].metadata.name}' ; echo \"\"<br>alertmanager-kube-prom-stack-kube-prome-alertmanager-db<br><br>## Get the pvc size request from the statefulset volumeClaimTemplate<br>$ kubectl get sts alertmanager-kube-prom-stack-kube-prome-alertmanager -o jsonpath='{.spec.volumeClaimTemplates[0].spec.resources}' | jq<br>{<br>  \"requests\": {<br>    \"storage\": \"2Gi\"<br>  }<br>}<br><br>## Verify the size of the pvc got from the statefulset volumeClaimTemplate<br>$ kubectl get pvc alertmanager-kube-prom-stack-kube-prome-alertmanager-db-alertmanager-kube-prom-stack-kube-prome-alertmanager-0 -o jsonpath='{.spec.resources.requests}' | jq<br>{<br>  \"storage\": \"2Gi\"<br>}</pre>\n<p>Storage is 2Gi which seems to be as per our provided custom-values.yaml \u2705</p>\n<ul>\n<li>Extend the persistent volume claim storage request viacustom-values.yaml.</li>\n<li>Modified custom-values.yaml</li>\n</ul>\n<pre>alertmanager:<br>  ingress:<br>    enabled: false<br><br>  podDisruptionBudget:<br>    enabled: false<br><br>  alertmanagerSpec:<br>    storage:<br>      volumeClaimTemplate:<br>        spec:<br>          accessModes: [\"ReadWriteOnce\"]<br>          resources:<br>            requests:<br>              storage: 5Gi ## Increased ##</pre>\n<p>The size is updated to 5Gi\u00a0, will apply the new values and monitor the\u00a0changes.</p>\n<ul><li>Helm upgrade with new\u00a0values.</li></ul>\n<pre>$ helm upgrade --install kube-prom-stack prometheus-community/kube-prometheus-stack --namespace kube-prom-stack --values custom-values.yaml<br>Release \"kube-prom-stack\" has been upgraded. Happy Helming!<br>NAME: kube-prom-stack<br>LAST DEPLOYED: Thu Nov 23 10:55:25 2023<br>NAMESPACE: kube-prom-stack<br>STATUS: deployed<br>REVISION: 2<br>NOTES:<br>kube-prometheus-stack has been installed. Check its status by running:<br>  kubectl --namespace kube-prom-stack get pods -l \"release=kube-prom-stack\"<br><br>Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create &amp; configure Alertmanager and Prometheus instances using the Operator.</pre>\n<ul><li>Check the details of the Persistent volume claim after updating the\u00a0size.</li></ul>\n<pre>## Get the pvc name from the statefulset volumeClaimTemplate<br>$ kubectl get sts alertmanager-kube-prom-stack-kube-prome-alertmanager -o jsonpath='{.spec.volumeClaimTemplates[0].metadata.name}' ; echo \"\"<br>alertmanager-kube-prom-stack-kube-prome-alertmanager-db<br><br>## Get the pvc size request from the statefulset volumeClaimTemplate (UPDATED)<br>$ kubectl get sts alertmanager-kube-prom-stack-kube-prome-alertmanager -o jsonpath='{.spec.volumeClaimTemplates[0].spec.resources}' | jq<br>{<br>  \"requests\": {<br>    \"storage\": \"5Gi\"<br>  }<br>}<br><br>## Verify the size of the pvc got from the statefulset volumeClaimTemplate (NOT-UPDATED)<br>$ kubectl get pvc alertmanager-kube-prom-stack-kube-prome-alertmanager-db-alertmanager-kube-prom-stack-kube-prome-alertmanager-0 -o jsonpath='{.spec.resources.requests}' | jq<br>{<br>  \"storage\": \"2Gi\"<br>}</pre>\n<p>Even though the volumeClaimTemplate of statefulset(alertmanager) is updated the persistent volume claim is using the old size 2Gi.\u00a0\u274c</p>\n<h4>Solution</h4>\n<p>The following steps are required to increase the size from 2Gito\u00a05Gi</p>\n<ul><li>\n<strong>STEP 1:</strong> In this case, the statefulset is managed via the operator and hence needs to be paused as well on the custom resource alertmanager</li></ul>\n<pre>## Get the name of alertmanager resource<br>$ kubectl get alertmanager<br>NAME                                      VERSION   REPLICAS   READY   RECONCILED   AVAILABLE   AGE<br>kube-prom-stack-kube-prome-alertmanager   v0.26.0   1          1       True         True        61m</pre>\n<pre>## Patch the resource , so that operator does not recreates it.<br>$ kubectl patch alertmanager/kube-prom-stack-kube-prome-alertmanager  --patch '{\"spec\": {\"paused\": true, \"storage\": {\"volumeClaimTemplate\": {\"spec\": {\"resources\": {\"requests\": {\"storage\":\"5Gi\"}}}}}}}' --type merge<br>alertmanager.monitoring.coreos.com/kube-prom-stack-kube-prome-alertmanager patched</pre>\n<ul><li>\n<strong>STEP 2:</strong> Patch the persistent volume claims associated with the statefulset.</li></ul>\n<pre>for p in $(kubectl get pvc -l alertmanager=kube-prom-stack-kube-prome-alertmanager -o jsonpath='{range .items[*]}{.metadata.name} {end}'); do \\<br>  kubectl patch pvc/${p} --patch '{\"spec\": {\"resources\": {\"requests\": {\"storage\":\"5Gi\"}}}}'; \\<br>done</pre>\n<ul><li>\n<strong>STEP 3:</strong> The final step is to delete the statefulset with the orphan strategy.</li></ul>\n<pre>$ kubectl delete sts alertmanager-kube-prom-stack-kube-prome-alertmanager --cascade=orphan</pre>\n<p><em>To verify if the PVC is extended.</em></p>\n<pre>## PVC is updated<br>$ kubectl get pvc alertmanager-kube-prom-stack-kube-prome-alertmanager-db-alertmanager-kube-prom-stack-kube-prome-alertmanager-0 -o jsonpath='{.spec.resources.requests}' | jq<br>{<br>  \"storage\": \"5Gi\"<br>}</pre>\n<p>By passing --cascade=orphan to kubectl delete, the Pods managed by the StatefulSet are left behind even after the StatefulSet object itself is\u00a0deleted.</p>\n<ul><li>\n<strong>STEP 4:</strong> Resume the operator to take control of the alertmanager provisioning. This step is valid in statefulsets managed via operators only.</li></ul>\n<pre>$ kubectl patch alertmanager/kube-prom-stack-kube-prome-alertmanager --patch '{\"spec\": {\"paused\": false}}' --type merge</pre>\n<h3>Conclusion</h3>\n<p>In Summary following steps need to be followed in the respective order to expand the persistent volume on statefulsets.</p>\n<ol>\n<li>Patch the statefulset with the required(expanded) volumeClaimTemplates configuration.</li>\n<li>Patch the persistent volume claims with the required(expanded) size configuration associated with the statefulset.</li>\n<li>Delete the statefulset with cascade=orphan strategy.</li>\n</ol>\n<p>And that concludes our exploration into the dynamic world of scaling storage for stateful applications in Kubernetes.</p>\n<p>Expanding the persistent volumes in statefulsets is a well-known restriction and is been tracked in the <a href=\"https://github.com/kubernetes/enhancements/issues/661\">Support Volume Expansion Through StatefulSets</a> and <a href=\"https://github.com/kubernetes/kubernetes/issues/68737\">StatefulSet: support resize pvc storage in K8s v1.11</a> GitHub issues in official Kubernetes repositories.</p>\n<h3>Acknowledgments</h3>\n<p>Thank you for embarking on this Kubernetes adventure with me. Scaling storage in Kubernetes can be complex, but you\u2019ve gained valuable insights to navigate this terrain. May your clusters be resilient, and your applications thrive. Happy reading, and until our next exploration!</p>\n<h3>Helpful Links</h3>\n<ul>\n<li><a href=\"https://kubernetes.io/blog/2022/05/05/volume-expansion-ga/\">Kubernetes 1.24: Volume Expansion Now A Stable\u00a0Feature</a></li>\n<li><a href=\"https://prometheus-operator.dev/docs/operator/storage/#resizing-volumes\">Resizing Prometheus Operator\u00a0Volumes</a></li>\n<li><a href=\"https://github.com/kubernetes/kubernetes/issues/68737\">StatefulSet: support resize pvc storage in K8s\u00a0v1.11</a></li>\n<li><a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#expanding-persistent-volumes-claims\">Expanding Persistent Volumes\u00a0Claims</a></li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ecd7cf75b754\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["technology","persistent-volume","statefulsets","kubernetes","devops"]}]}